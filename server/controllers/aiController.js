const {getFileContent}= require("../services/githubService.js");
const aiService=require("../services/aiService.js");

//In-memory cache for ai file understanding
const fileAIcache= new Map();

//Generate file intelligence(runs once per file)
exports.analyzeFile=async(req,res)=>{
    try{
        console.log("ğŸ” analyzeFile called");
        const{owner,repo}=req.params;
        const {path}=req.body;

        console.log("ğŸ“¦ Params:", {owner, repo, path});

        if(!path){
            return res.status(400).json({message:"File path required"});
        }

        const cacheKey=`${owner}/${repo}:${path}`;

        //Cache hit->instant response
        if(fileAIcache.has(cacheKey)){
            console.log("âœ… Cache HIT");
            return res.json({
                source:"cache",
                data:fileAIcache.get(cacheKey),
            });
        }

        console.log("ğŸ“¥ Fetching file content...");
        //Fetch raw code(reuse your existing logic)
        const code=await getFileContent(owner,repo,path);
        console.log("âœ… Got code, length:", code.length);

        //Truncate for AI safety
        const MAX_AI_CHARS=4000;
        const truncatedCode=code.slice(0,MAX_AI_CHARS);
        console.log("âœ‚ï¸ Truncated to:", truncatedCode.length);

        console.log("ğŸ¤– Calling AI service...");
        //Call AI
        const intelligence=await aiService.generateFileIntelligence(truncatedCode);
        console.log("âœ… AI Response received:", intelligence?.substring(0, 100));

        //Save to cache
        fileAIcache.set(cacheKey,intelligence);

        res.json({
            source:"ai",
            data:intelligence,
        });
    }catch (err) {
  console.error("âŒ AI ERROR FULL:", err);
  console.error("Stack:", err.stack);
  res.status(500).json({
    message: "AI analysis failed",
    error: err.message,
    stack: err.stack
  });
}

};

exports.askQuestion=async(req,res)=>{
    try{
      console.log("ğŸ” askQuestion called");
      const{owner,repo}=req.params;
      const{path,question}=req.body;

      console.log("ğŸ“¦ Params:", {owner, repo, path, question});

      if(!path||!question){
        return res.status(400).json({message:"Path and question are required"});
    }

    const cacheKey=`${owner}/${repo}:${path}`;
    const intelligence=fileAIcache.get(cacheKey);

    if(!intelligence){
        console.log("âŒ No intelligence in cache for:", cacheKey);
        console.log("Available keys:", Array.from(fileAIcache.keys()));
        return res.status(400).json({
            message:"File not analyzed yet. Analyze file first."
        });
    }

    console.log("ğŸ¤– Asking AI...");
    const answer=await aiService.answerQuestion(intelligence,question);
    console.log("âœ… Got answer:", answer?.substring(0, 100));
    res.json({answer});

    }catch(err){
        console.error("âŒ Error:", err.message);
        console.error("Stack:", err.stack);
        res.status(500).json({message:"Failed to answer question", error: err.message});
    }
};

exports.askQuestionStream = async (req, res) => {
  console.log("ğŸ” askQuestionStream called");
  const { path, question } = req.body;
  console.log("ğŸ“¦ Stream params:", {path, question});

  res.setHeader("Content-Type", "text/event-stream");
  res.setHeader("Cache-Control", "no-cache");
  res.setHeader("Connection", "keep-alive");

  try {
    console.log("ğŸ¤– Getting stream...");
    const stream = await aiService.answerQuestionStream(path, question);
    console.log("âœ… Stream created");

    let chunkCount = 0;
    for await (const chunk of stream) {
      chunkCount++;
      console.log(`ğŸ“¤ Chunk ${chunkCount}:`, chunk.substring(0, 50));
      res.write(`data: ${chunk}\n\n`);
    }

    console.log(`âœ… Stream complete. Total chunks: ${chunkCount}`);
    res.write("data: [DONE]\n\n");
    res.end();
  } catch (err) {
    console.error("âŒ Stream error:", err);
    console.error("Stack:", err.stack);
    res.write(`data: âš ï¸ Streaming failed: ${err.message}\n\n`);
    res.end();
  }
};